{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import networkx as nx\n",
    "import tqdm.notebook as tqdm\n",
    "from plotly import graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compute some auxiliary dictionaries. To help mapping names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"ENTER-HERE-OUTPUT-FILE.csv\" #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = pd.read_json(\"./stations.json\")\n",
    "\n",
    "\n",
    "for k  in df_stations[\"list\"][0].keys():\n",
    "    \n",
    "    df_stations[k] = df_stations[\"list\"].apply( lambda x : x[k] )\n",
    "df_stations = df_stations.drop( [\"list\"] , axis = 1 )\n",
    "\n",
    "#df_stations = df_stations[ df_stations[\"description\"] != \"Hakaniemen kauppahalli 1\" ]\n",
    "serial2name = dict()\n",
    "name2pos = dict( )\n",
    "for x , y  in df_stations.iterrows():\n",
    "    serial2name[ y[\"serial\"]] = y[\"description\"]\n",
    "    name2pos[ y[\"description\"] ] = ( y[\"latitude\"] , y[\"longitude\"] )\n",
    "name2serial = {v: k for k, v in serial2name.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function build_graph takes the data frame retrieved from the API and builds a graph, based on the occurences of unique hashes. We keep track of each unique hash and count if the hash is seen by other station at a future time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph( df_ ):\n",
    "    graph = nx.MultiDiGraph() \n",
    "    #graph.add_nodes_from(   [  serial2name[x] for x in  df_[\"serial\"].unique() ]  )\n",
    "    for  i , x in  tqdm.tqdm( df_.iterrows() ) :\n",
    "\n",
    "        node1 = x[ \"serial\" ]\n",
    "        name1 = serial2name[ node1 ]\n",
    "        hash1 = x[\"hash\"]\n",
    "        next_data = df[ i: ]\n",
    "        next_data = next_data[ next_data[\"time\"] != x[\"time\"] ]   #\n",
    "        next_data = next_data[ next_data[\"hash\"] == hash1 ]\n",
    "        next_data = next_data[ next_data[\"serial\"] != node1 ]\n",
    "        if ( len( next_data) != 0 ):\n",
    "            next_stations = next_data[\"serial\"]\n",
    "            edges = []\n",
    "            for s in next_stations:\n",
    "                name2 = serial2name[s]\n",
    "                edges.append(   ( name1  , name2 ) )\n",
    "            #print( edges )\n",
    "            graph.add_edges_from(  edges )\n",
    "            \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "for f in files[:]:\n",
    "\n",
    "    df = ... # logic to read the dataframe\n",
    "    df = df.drop_duplicates( subset =[\"hash\" , \"serial\"] )\n",
    "    g = build_graph( df )\n",
    "    graphs.append( g )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_edges = []\n",
    "for g in graphs:\n",
    "    total_edges += g.edges\n",
    "    \n",
    "total_graph = nx.MultiDiGraph()\n",
    "total_graph.add_edges_from( total_edges )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix( total_graph, nodelist=total_graph.nodes ).todense()#.shape\n",
    "nodes = total_graph.nodes\n",
    "df_A = pd.DataFrame( A )\n",
    "df_A.columns = [  name2serial[ x] for x in nodes ]  \n",
    "df_A.index =  [  name2serial[ x] for x in nodes ]\n",
    "df_a.to_csv(output , index = False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
